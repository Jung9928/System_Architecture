# Gateway 란?

### 개념도 <br>
![img.png](img.png)

<br><br>

### 0. API 게이트웨이의 등장 배경
- 많은 서비스들이 발전/개선되며 점차 규모가 확장되고 복잡해짐. <br> 
  `어떻게 하나의 시스템에서 많은 서비스들을 독립적인 기능을 수행하는 작은 단위로 서비스할 수 있을까?`라는 고민 끝에 나온 것이 MSA. <br>
  하지만, 이 MSA에서도 서비스의 작은 단위가 50개, 100개가 넘어가면 End-Point 관리가 어려워지고 <br>
  각각의 서비스의 공통기능(ex : 인증/인가, 로깅 등)들을 중복 개발해야 하는 문제가 발생. <br><br>

  이러한 문제를 해결하고자 나온 것이 `API Gateway`이다.

<br><br>


### API 게이트웨이(API Gateway)란?
- 클라이언트와 각 서비스들 사이에 위치하여 클라이언트의 요청을 API Gateway가 받아서 <br>
  설정에 따른 각 엔드포인트로 클라이언트를 대신하여 서비스들에게 요청을 전달하고 <br>
  서비스로부터 결과를 응답받으면 이를 클라이언트에게 전달하는 `프록시(Proxy)` 역할을 수행함. <br><br>

  당연히, 요청과 응답을 API 게이트웨이가 전담하므로 클라이언트는 내부 서비스의 아키텍처를 알 수 없게됨으로써 <br>
  자연스럽게 프록시의 장점 중 하나인 `캡슐화`의 특징을 가짐 -> 정보 은폐 <br><br> 

  위와 같이 클라이언트의 요청을 라우팅하는 것 외에도 `단일 진입점`의 이점으로 인해 추가로 구현할 경우, 장점이 많음. <br>
  
<br><br>

### 2. API 게이트웨이의 주요기능
#### 1) 인증/인가 및 토큰 발급 <br>
![img_2.png](img_2.png)

- 인증/인가의 경우, 각 서비스마다 공통으로 구현되어야 하는 필수적인 기능 <br>
  각 서비스 마다 인증/인가 처리 구현 시, 매우 비효율적 -> `API Gateway`에서 처리하도록 일임. <br>
  (ex : Spring에서 각 서비스에 Spring Security 의존성을 추가해 해당 기능을 구현하는 것) <br><br>
  
  또한, API 사용을 위한 토큰 발급 기능도 마찬가지 이유로 `API Gateway`에서 처리 <br>
  실제로 토큰 발급 기능은 인증을 위한 서비스(인증서버)를 하나 두고 처리되게끔 함. <br><br>


#### 2) 공통 로직 처리 <br>

![img_3.png](img_3.png) | ![img_4.png](img_4.png)
---|---|

- 인증/인가 외에도 여러 서비스에서 공통적으로 처리해야 할 기능은 많음. <br>
  공통된 기능을 각 서비스마다 구현하는 것은 생산성/유지보수성 비효율적 <br><br>

  공통 로직의 경우 `API Gateway`에서 구현되는 것이 효율적 -> 개발 중복을 줄일 수 있고 `표준 준수`도 쉬움. <br><br>



#### 3) 로드 밸런싱
- 대용량 처리 서비스에 있어서 로드밸런싱은 필수적. <br> 
  기본적으로 여러 개의 API 서버를 두어 부하 분산하는 기능으로 쓰이지만, <br>
  API 서버 장애 시, 이를 감지해서 로드밸런싱 리스트에서 빼고, 복구되었을 때 다시 로드밸런싱 리스트에 넣는 기능들이 필요 (health-Check)

<br><br>

#### 4) 메디에이션(Mediation)
- 클라이언트에서 호출하는 요청과 API 서버가 제공하는 API의 스펙에 차이가 발생 시, 이를 중간에서 중재하는 기능을 의미. <br><br>
- 메디에이션 기능 중, 메세지 호출 변화(Message Exchange Pattern)가 있음. <br>
  메세지 호출 패턴은 동기(Sync), 비동기(Async)와 같은 API를 호출하는 메세지 패턴을 정의하는 것. <br>
  API Gateway를 이용하면 다음과 같이 `동기 호출` -> `비동기 호출`로 변경 가능함. <br>
![img_5.png](img_5.png)

<br><br>




### 2-1. 용도
- 클라이언트 보호 (익명성)
    - 서버에서 받는 IP는 유저의 IP가 아니라, 프록시 서버의 IP이므로 유저의 IP주소와 신원을 숨길 수 있어 익명성과 개인 정보 보호 효과가 있음 <br><br>

- 캐싱
    - 유저가 동일한 컨텐츠에 대해 다시 요청을 할 경우, 프록시는 원본 서버에 요청을 전달하는 대신 캐싱된 컨텐츠를 제공. <br><br>

    - 예를 들어, 100만명의 유저가 www.naver.com에 접근한다면, 본래 웹서버는 동일한 절차를 100만회 실행해야 하지만 <br>
      정적 데이터의 경우, 유저 별 응답이 달라질 필요가 없으므로 `포워드 프록시`를 활용해 프록시 내 캐싱된 페이지를 로드함. <br>
      이를 통해, 클라이언트의 입장에선 빠르게 컨텐츠를 응답받을 수 있고 서버의 입장에선 불필요한 로드 감소로 인해 부하 완화 효과가 있음 <br><br>


- 특정 콘텐츠에 대한 액세스 차단
    - 액세스 제어 정책을 설정해서 특정 사이트나 컨텐츠에 대한 액세스를 제한할 수 있음 <br>
      이를 통해, 조직이나 기관에서 인터넷 사용을 관리하거나 악성 컨텐츠 필터링이 가능 <br><br>

<br>



### 3. 리버스 프록시(Reverse Proxy)란 ?
![img_3.png](img_3.png)

- 인터넷망에 있는 클라이언트가 프록시 서버를 호출하여 내부망에 있는 서버를 호출하면 `리버스 프록시`임. <br>
  즉, 리버스 프록시는 서버의 앞단에 위치하여 클라이언트 요청을 여러 대상 서버로 분산하여 전달하는 역할 수행. <br><br>

- ex) <br>
  FATC.CLUB 웹서비스엔 3개의 서버가 존재
    - fatc.club : 블로그 담당 서버
    - etc.fatc.club : 블로그 내용 구현하여 보여주는 서버
    - ip.fatc.club : IP 제공 서비스 수행 서버
      <br><br>

모든 요청은 1개의 Proxy 서버를 통해 들어온다고 했을 때, 어떻게 1~3번 서버를 구분해야 할까? <br>
=> `도메인`을 보고 어떤 서버로 해당 요청을 전달할 지 결정함.

![img_7.png](img_7.png)

이처럼 다수의 서버를 Proxy 서버 하단부에 위치시켜두고 <br>
특정 조건(도메인)에 맞는 요청을 적절한 서버에게 전달해주는 역할을 수행하는 것이 `Reverse Proxy`임. <br><br>

한가지 명심할 것 => 하나의 `Proxy`서버는 `Reverse`와 `Forward`를 모두 수행할 수 있음. <br>
다만, 하나로 모든 것을 처리하기엔 부담되므로 둘로 나눈 것. <br><br>

`Reverse Proxy`를 이용하게 되면, 하나의 `프록시`로 다수의 서버(동일 서비스 or 다른 서비스던 상관 X) 요청 처리가 가능 <br>
이로 인한 장점 중, 라이트 유저에게 가장 큰 장점은 1개의 IP로 다수의 웹 서비스 수행이 가능함. <br>
이러한 프록시 기능은 대다수의 HTTP 프레임워크에서 제공함 (ex : Apache, NginX 등) <br><br>





### 3-1. 장점
1) 서버 측면에서의 장점
    - 포워도 프록시의 캐싱 기능과 서버 load 부하 감소
        - 프록시의 본래 역할은 자주 사용되는 데이터를 확보해두고 이를 캐싱(재활용)하는 것 -> 서버의 load 부하 감소 효과 <br><br>

    - 하나의 IP, 다수의 웹 서비스 사용자가 특정 도메인으로 요청 전송 시, <br>
      대부분의 DNS는 도메인 별 등록된 IP의 Well-known 포트 80(HTTP), 443(HTTPS)로 요청을 릴레이 함. <br><br>

      즉, 도메인 1개 <-> IP 1개 <-> 서버 1개, 이렇게 구성하는게 일반적이겠지만 <br>
      한정된 IP 수량(IPv4 일 경우)과 가격 측면 그리고 관리 용이성 등 다양한 이유로 1개의 IP로 다수의 웹서버 동작 가능. <br><br>

      이 말은 곧 여러 개의 서버나 어플리케이션을 하나의 도메인으로 통합 가능함을 의미 <br>
      -> 다양한 어플리케이션을 단일 진입점(entry point)에서 관리할 수 있으며, URL 라우팅, SSL 인증서 관리 등을 수행 가능 <br><br>

- 실제 서버에 직접적인 접근 차단
    - 외부에 노출되는 IP는 프록시 서버의 공인 IP이며, 실제 동작하는 서버는 사설 IP를 할당받아 동작함. <br>
      따라서, 망 분리를 통해 클라이언트가 직접적으로 서버의 IP를 알 수 없기 때문에 보안이 다소 취약한 HTTP 프레임워크를 숨겨 이를 보호할 수 있음 <br>
      다만, 100% 보안이 완벽하진 않음. <br><br>

- 리버스 프록시 뒤에 여러 개의 WAS를 두어, 사용자의 요청을 분산할 수 있음 <br>
  앤드포인트(URL)마다 호출 서버를 설정할 수 잇어 역할에 따라 서버의 트래픽을 분산할 수 있음 <br><br>

- 정적 콘텐츠 캐싱처리
    - 자주 요청되는 컨텐츠를 저장 -> 동일한 요청에 대해 캐싱된 응답 제공 <br><br>




2) 클라이언트 측면에서의 장점
- 클라이언트의 요청을 받아 프록시 서버가 백엔드 서버의 특정 서비스에 접근하게 되면 <br>
  클라이언트의 IP가 전달되는 것이 아닌 프록시 서버의 IP가 요청과 함께 백엔드 서버에 전달되므로 클라이언트 정보가 캡슐화된다는 장점이 있음.


<br><br>



### 자료 인용 출처
ref : https://jcdgods.tistory.com/322#none